{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JTxsWF-5sXG"
   },
   "source": [
    "\n",
    "# [KDT] ch6 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression / Decision Tree / Naive Bayes / KNN \n",
    "\n",
    " - 데이터셋: 직장인 연봉 정보 / 붗꽃 / 다이아몬드 / 타이타닉  \n",
    " - 주요 라이브러리: sklearn linear_model / \n",
    " - 알파 퀴즈(1개) / 파이 퀴즈(1개) / 시그마 퀴즈(2개) / 오메가 퀴즈(과제 1개) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1668725561526,
     "user": {
      "displayName": "jinyang park",
      "userId": "06576046992691541404"
     },
     "user_tz": -540
    },
    "id": "Dtoe4P7Hwi_G"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1006,
     "status": "ok",
     "timestamp": 1668725562530,
     "user": {
      "displayName": "jinyang park",
      "userId": "06576046992691541404"
     },
     "user_tz": -540
    },
    "id": "2P_tOya1wwd_"
   },
   "outputs": [],
   "source": [
    "# 파일 로딩 \n",
    "df_hk = pd.read_csv('.\\\\data\\\\hk_221206.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\alpha$(알파) 퀴즈: \n",
    "<br>직장인 데이터셋과 해당 인원들의 차량 소유 데이터셋을 바탕으로 분류 분석을 계획 중이다. \n",
    "<br>이를 위해 먼저 분류 분석을 위한 전처리 과정을 진행하고자 한다.\n",
    "\n",
    "<br>기본 데이터셋 df_hk에 차량 소유 데이터셋을 join한다.( 차량 소유 데이터 파일은 hk_221206_car.csv 이며 left 조인) \n",
    "<br>차량 정보는 배기량에 의해 A/B/C/D/E/F 타입으로 되어 있으며 차량이 없는 경우 none으로 되어 있다. \n",
    "<br>6개 차량 타입을 A, B 인 경우 SS로 변경, C, D 인 경우 MM로 변경, E, F인 경우 LL로 변경한다.(컬럼명은 car_type 동일)\n",
    "<br>car_type이 none인 경우 결측치로 판단하여 제외한다. \n",
    "<br>전처리 후 데이터 셋 명칭을 basetable1으로 명명한다. \n",
    "<br>\n",
    "<br><b>문제: car_type별 연봉 평균을 각각 구하시오(SS/MM/LL 3가지 경우 확인) </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hk[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car 파일 로딩 \n",
    "df_hk_car = pd.read_csv('.\\\\data\\\\hk_221206_car.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hk_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge, left join  or concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map or replace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 로지스틱 회귀분석 워밍업\n",
    "\n",
    "<br> <진행순서>\n",
    "<br> basetable1 236개 샘플을 활용하여 \n",
    "<br> 1. 종속변수를 gender\n",
    "<br> 2. 독립변수 height, age, salary, expenditure 4개로 구성하는 로지스틱 회귀분석을 설계 \n",
    "<br> 3. 독립변수 4개별 회귀계수를 확인하시오 \n",
    "<br>\n",
    "<br>from sklearn.linear_model import LogisticRegression 활용 \n",
    "<br>(파라미터 가이드: Seed=1234, Solver='newton-cg', 나머지: Default)\n",
    "<br>\n",
    "\n",
    "### Chat GPT\n",
    "\n",
    "Q) solver의 역할이 뭔가요\n",
    "\n",
    "A) \n",
    "solverLogisticRegression최적화에 사용할 알고리즘을 지정하는 scikit-learn 클래스의 매개변수입니다 . 즉, 모델에 대한 최상의 계수를 찾는 데 사용되는 방법을 결정합니다.\n",
    "\n",
    "솔버의 선택은 속도와 정확도 측면에서 모델의 성능에 큰 영향을 미칠 수 있습니다. 일부 솔버는 더 작은 데이터 세트에 더 적합하고 다른 솔버는 더 큰 데이터 세트 또는 많은 수의 기능이 있는 데이터 세트에 더 적합합니다.\n",
    "\n",
    "scikit-learn에서 사용 가능한 솔버는 'newton-cg', 'lbfgs', 'liblinear', 'sag' 및 'saga'입니다. 각 솔버에는 고유한 강점과 약점이 있으므로 문제에 적합한 솔버를 선택하는 것이 중요합니다. 예를 들어 'newton-cg' 및 'lbfgs'는 많은 수의 기능이 있는 문제에 적합한 선택인 반면 'liblinear'는 더 작은 데이터 세트에 적합한 선택입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1) LogisticRegression 클래스 호출\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# step2) ['gender','height', 'age', 'salary', 'expenditure'] df_hk 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2) LogisticRegression 모델생성,  Seed=1234, Solver='newton-cg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression 모델 attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names_in_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3) 독립변수 4개별 회귀계수(coef) 확인\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신장이 1cm 늘어날시 결과에 미치는 영향력이 0.3775이 아님에 유의 \n",
    "<br> 로그가 붙어 있는 오즈비이기 때문에 타깃에 미치는 영향력을 직관적으로 알기 위해서는 로그를 떼어내고 해석해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$ Log \\left\\{ \\frac{ p  }{ 1-p   }\\right\\}  = -62.4681 + 0.3775\\times height + (-0.0571)\\times age + (-0.0001) \\times salary + 0.0004 \\times expenditure $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 관련 식을 Target 관련 확률로 변환 \n",
    "#### $$ p = \\frac{1}{1+\\exp(-1\\times(-62.4681 + (0.3775)\\times height + (-0.0571)\\times age + (-0.0001) \\times salary + 0.0004 \\times expenditure))} $$\n",
    "p 가 0.5 이상일 경우 1 / 0.5 미만이면 0으로 분류(cut-off 임계치는 수정 가능) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfMi2HeL4piH"
   },
   "source": [
    "\n",
    "## 1-0. 로지스틱 회귀분석 statemodels 활용\n",
    "\n",
    "특정 자동차 모델 예측모델 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basetable1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <진행순서>\n",
    "<br>1. 전체 데이터 셋 중 차량 소유자만 대상 (미소유자 drop)\n",
    "<br>2. 종속변수 : car_type LL을 1로 나머지는 0으로 변환한 후 car_type 변수에 그대로 저장 할 것 \n",
    "<br>3. 독립변수 : 성별, 회사 2개의 명목형 변수를 더미 변수화( drop_first 옵션 Ture) 독립변수 총 개수는 수치형 4개 더미 3개 총 7개 \n",
    "<br>4. 로지스틱 회귀분석 모델을 만드시오. 라이브러리 및 메소드는 statsmodels.formula.api 활용 할 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# step1) car_type null 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2) car_type 변경 (LL -> 1, else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3) 성별, 회사 2개의 명목형 변수 더미 변수화( drop_first 옵션 Ture) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# step4) 로지스틱 회귀분석 모델\n",
    "# case1) statsmodels.formula.api\n",
    "\n",
    "from statsmodels.formula.api import logit\n",
    "# formula 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# case2) statsmodels.api\n",
    "# sm.add_constant intercept\n",
    "\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "statsmodels sm 라이브러리의 Logit 메소드는 확률 값으로 도출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict 확률값을 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict 확률값을 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1-1. 로지스틱 회귀분석 sklearn 라이브러리 활용 1\n",
    "\n",
    "<br> <진행순서>\n",
    "<br>1. basetable1을 사용하시오.\n",
    "<br>2. 종속변수 : car_type LL을 1로 나머지는 0으로 변환한 후 car_type 변수에 그대로 저장 할 것 \n",
    "<br>3. 독립변수 : 'salary', 'expenditure' 2개 \n",
    "<br>4. 로지스틱 회귀분석 모델을 만드시오. 라이브러리 및 메소드는 sklearn 활용 할 것 (C=100000 ,solver='newton-cg')\n",
    "<br> 설명: C=100000: 정규화(L1, L2규제) 강도의 역수; 양의 실수, 값이 작을수록 더 강력한 정규화 지정\n",
    "<br>5. 로지스틱 회귀분석 모델로 예측했을때 맞춘것과 틀린 갯수는"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1) basetable1로 df_hk 생성\n",
    "df_hk1_1 = basetable1[['car_type','salary', 'expenditure']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2) car_type 변경 (LL -> 1, else 0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step4) sklearn 로지스틱 회귀분석 모델 (C=100000 ,solver='newton-cg') \n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀 attributes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀 coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 \n",
    "sns.scatterplot( x=\"salary\", y=\"expenditure\", hue = 'car_type', data =df_hk1_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$ Log \\left\\{ \\frac{ p  }{ 1-p   }\\right\\}  = -9.8831 + 0.0003\\times salary + 0.0011\\times expenditure $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 관련 식을 Target 관련 확률로 변환 \n",
    "### $$ p = \\frac{1}{1+\\exp-1\\times(-9.8831+(0.0003)\\times salary + 0.0011 \\times expenditure))} $$\n",
    "p 가 0.5 이상일 경우 1 / 0.5 미만이면 0으로 분류(cut-off 임계치는 수정 가능) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확률(p) 계산식\n",
    "def linear(x1, x2):\n",
    "    p = 1 / ( 1+ np.exp(-1 * (-9.883112+(0.000284)*x1+(0.001069)*x2)))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# row 3 데이터\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row 3 데이터 확률(p) 계산\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row 149 데이터\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row 149 데이터 확률(p) 계산\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#row 3에 대한 확률\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#row 149에 대한 확률\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#row 3에 대한 로지스틱 회귀분석 예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#row 149에 대한 로지스틱 회귀분석 예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step5) 로지스틱 회귀분석 예측 평가, 예측중 맞춘것과 틀린 갯수는\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 시각화\n",
    "fig, ax = plt.subplots( nrows= 1 , ncols=2, figsize=(14, 5))\n",
    "sns.scatterplot( data = df_hk1_1, x='salary', y='expenditure', hue = 'car_type',  palette='Set1', ax=ax[0] )\n",
    "sns.scatterplot( data = df_hk1_1, x='salary', y='expenditure', hue = 'pred_1_1',  palette='Set2', ax=ax[1] )\n",
    "\n",
    "ax[0].set_title('car_type')\n",
    "ax[1].set_title('pred_1_1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1-1. $\\pi$(파이) Quiz  로지스틱 회귀분석 sklearn 라이브러리 활용 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><실행순서>\n",
    "<br> 1. basetable1을 사용하여 (236 rows × 11 columns) \n",
    "<br> 2. 종속변수 : 파생변수('target')을 생성하시오. car_type( LL 여부 yes:1, no:0) \n",
    "<br> 3. 독립변수 : salary, expenditure, company(dummy변수화, drop_first=True)\n",
    "<br> 4. sklearn을 사용하여 로지스틱 회귀모델을 만들고 독립변수별 회귀계수를 구하시오 (C=100000 ,solver='newton-cg')\n",
    "<br> 5. salary ( 6660 ), expenditure ( 5285 ), company(B) 일때 값을 예측하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basetable1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1) df_hk생성\n",
    "\n",
    "# step2) 파생변수('target') 생성. car_type( LL 여부 yes:1, no:0)\n",
    "\n",
    "# value_counts 로 확인\n",
    "\n",
    "# step3) 독립변수 salary, expenditure, company(dummy변수화, drop_first=True)\n",
    "\n",
    "# 로지스틱 회귀모델 생성(C=100000 ,solver='newton-cg'), 회귀계수 \n",
    "\n",
    "# intercept_\n",
    "\n",
    "# coef_\n",
    "\n",
    "# feature_names_in_\n",
    "\n",
    "# 회귀계수\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 회귀계수 산출식 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $ Log \\left\\{ \\frac{ p  }{ 1-p   }\\right\\}  = \\beta_0 + \\beta_1X $ &emsp; →&emsp;&emsp;   $ p = \\frac{1} {1 + e^{-(\\beta_0 +\\beta_1X)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 바탕으로 산출식에 적용 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Log \\left\\{ \\frac{ p  }{ 1-p   }\\right\\}  = -28.989 + 0.003\\times salary + 0.001\\times expenditure + 3.956\\times company B + (-7.756) \\times company C $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 식을 target 1에 해당하는 확률값으로 변환하면?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ p = \\frac{1}{1+\\exp(-1\\times(-28.989 + 0.003\\times salary + 0.001\\times expenditure + 3.956\\times company B + (-7.756) \\times company C))} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1668725563411,
     "user": {
      "displayName": "jinyang park",
      "userId": "06576046992691541404"
     },
     "user_tz": -540
    },
    "id": "yOu0_IsLU8Ix",
    "outputId": "a17180ac-b00a-4624-b7f9-7828babd8edb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 회귀식 예측\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "회귀식을 바탕으로 확률값 도출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀식 logistic_linear\n",
    "def logistic_linear(x1, x2, x3, x4):\n",
    "    p = 1 / ( 1+ np.exp(-1 * (-28.989+(0.0026)*x1+(0.001235)*x2+(3.955891)*x3)+(-7.756401)*x4))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data , df_hk1_2_dum.drop('target', axis=1).tail(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba로 확인, tail(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자 정의 함수를 통해 독립변수 값을 넣어주면 그에 해당하는 확률 값을 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀식으로 확인 (8760, 7385, 0, 0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀식으로 확인 (7470, 6095, 0, 0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step5) 회귀식으로 salary ( 6660 ), expenditure ( 5285 ), company(B) 일때 값 예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step5) predict, predict_proba로 ( 6660 ), expenditure ( 5285 ), company(B) 일때 값 예측\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2 로지스틱 회귀분석 평가 1/2\n",
    "\n",
    "df_hk1_2_dum 데이터셋을 바탕으로 train test 셋 7:3으로 분할\n",
    "<br> 해당 모델을 바탕으로 얼마나 정확하게 분류하는지 평가 \n",
    "<br> Accuracy, Precision, Recall, F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_hk1_2_dum[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test로 분할\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy = $$\\frac{TP+TN}{TP+TN+FP+FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision = $$\\frac{TP}{TP+FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall = $$\\frac{TP}{TP+FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 = $$\\frac{2\\times Precision \\times Recall}{Precision+Recall}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# crosstab(predict_1, df_hk_test_1['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가지표 계산\n",
    "accuracy_s = \n",
    "precision_s = \n",
    "recall_s = \n",
    "f1_s = \n",
    "\n",
    "print('accuracy_s =', accuracy_s)\n",
    "print('precision_s =', precision_s)\n",
    "print('recall_s =', recall_s)\n",
    "print('f1_s =', f1_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가지표 계산\n",
    "# y_true, y_pred 순서 중요\n",
    "\n",
    "print( \"Accuracy : \", )\n",
    "print( \"Precision : \", )\n",
    "print( \"Recall : \", )\n",
    "print( \"F1 : \", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_report\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1-2 로지스틱 회귀분석 평가 2/2 \n",
    "\n",
    "ROC AUC score 도출\n",
    "<br>ROC curve 도출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba중 1의 확률 도출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba중 1의 확률\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curve 도출 \n",
    "<br> <b>x축  FPR</b> = FP / (FP + TN) = 1 - TNR = 1 - 특이성\n",
    "<br> <b>y축  TPR</b> = Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화, roc_curve \n",
    "plt.plot( fprs, tprs, label='ROC') #ROC 곡선 그리기\n",
    "plt.plot([0,1], [0,1], 'k--', label='Random') # 가운데 대각선 그리기 \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3 로지스틱 회귀 분석 다항 분석 \n",
    "\n",
    "회사 예측 하기  \n",
    "로지스틱 회귀 분석시 타깃 항목값은 0 또는 1이었다. 만약 타깃 종류가 2가지가 아닌 3가지 이상이면 어떻게 해야 할까? \n",
    "\n",
    "<br><b>종속변수</b> : car_type(SS/MM/LL) \n",
    "<br><b>독립변수</b> : age, salary, expenditure, company(drop_first=True)\n",
    "\n",
    "옵션값 - C=100000 , solver='newton-cg' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basetable1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hk생성, car_type, age, salary, expenditure, company(drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test분리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다항 로지스틱회귀 모델 생성, multi_class='multinomial' or default auto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다항 로지스틱회귀 모델 예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다항 로지스틱회귀 모델 예측값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 다항 로지스틱회귀 모델 예측값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다항 로지스틱회귀 모델 평가표\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. $\\pi$(파이) Quiz 로지스틱 회귀분석 - 붓꽃 데이터 셋 활용 \n",
    "sklearn 라이브러리 활용을 통한 붓꽃 품종 분류 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로딩\n",
    "df_iris = pd.read_csv('.\\\\data\\\\iris.csv')\n",
    "df_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "fig = plt.figure( figsize=(6,6))\n",
    "\n",
    "sns.scatterplot( x='sepal_length', y='petal_length', hue='species', data= df_iris)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>1. 종속변수는 species, species가 virginica 여부인지 구분하는 파생변수('target') 를 만드시오 \n",
    "<br>2. 독립변수는 'sepal_length', 'sepal_width',\t'petal_length',\t'petal_width' 4개 변수로 하되 \n",
    "       정규화(StandardScaler)하여 사용하시오 \n",
    "<br>3. train, test 분류할 필요 없이 150개 샘플을 사용하고 150개 샘플 그대로 로지스틱 회귀모델에 적용해 예측하시오\n",
    "<br>4. virginica 예측 분류 모델 관련 재현율을 구하시오\n",
    "<br>( sklearn.liner_model LogisticRegression 활용 파라미터 값 C=100000 , random_state = 123, solver='newton-cg' 나머지 디폴트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1) 종속변수 species 중 virginica 여부 를 분류하는 파생변수('target') 생성\n",
    "\n",
    "\n",
    "# value_counts로 확인\n",
    "\n",
    "\n",
    "# step2) 'sepal_length', 'sepal_width', 'petal_length', 'petal_width' 정규화(StandardScaler)\n",
    "\n",
    "\n",
    "# StandardScaling df화\n",
    "\n",
    "\n",
    "# step3) LogisticRegression\n",
    "\n",
    "\n",
    "# step3) LogisticRegression predict\n",
    "\n",
    "\n",
    "# step4) recall_score\n",
    "\n",
    "# crosstab 확인\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3_1. Decision Tree (DecisionTreeClassifier)\n",
    "\n",
    "<br><b>종속변수</b> : car_type\n",
    "<br><b>독립변수</b> : gender, height, age, salary, expenditure, company(명목변수 모두 더미변수화)\n",
    "<br>train_test_split(random_state=123, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로딩\n",
    "basetable1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy ('gender', 'company')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df_hk_3, test_df_hk_3 = train_test_split( df_hk3, random_state=123, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier 호출\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importances_  종속변수(car_type에 영향을 미치는 정도) -> feature_importances_로 분기 한다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importances_시각화\n",
    "sns.barplot( x='imp', y='feature', data=model_imp.head(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_tree 시각화\n",
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(35,10))\n",
    "a = plot_tree(model_3, \n",
    "              feature_names= model_3.feature_names_in_,          # feature_names display\n",
    "              class_names =  train_df_hk_3['car_type'].unique(), # class_names display\n",
    "              filled=True,                                       # color\n",
    "              rounded=True,\n",
    "              max_depth= 4,                                      # display max_depth= 4\n",
    "              fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최초 165개 데이터셋 중 expenditure <= 4242.5 69개 샘플 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#69개 데이터셋 중 age <= 37.5 인경우\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#69개 데이터셋 중 age > 37.5 인경우\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# classification_report (tree)\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "# 시각화\n",
    "fig = plt.figure( figsize=(6,6))\n",
    "\n",
    "sns.scatterplot( x='age', y='expenditure', hue='car_type', data= train_df_hk_3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3_2. $\\pi$(파이) Quiz Decision Tree (DecisionTreeRegressor)\n",
    "\n",
    "<br><실행순서>\n",
    "<br>basetable1을 사용\n",
    "<br>1.<b>종속변수</b> : expenditure\n",
    "<br>2.<b>독립변수</b> : gender, height, age, salary, company(명목변수 모두 더미변수화)\n",
    "<br>3.train_test_split(random_state=123, train_size=0.7)\n",
    "<br>4.test data에 대해 예측하고 mean_squared_error를 구하시오 \n",
    "<br>5.DecisionTreeRegressor사용 (DecisionTreeRegressor( max_depth= 4, min_samples_split= 5, random_state= 1234))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로딩\n",
    "basetable1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth= 4\n",
    "# dummy ('gender', 'company')\n",
    "\n",
    "\n",
    "# train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# DecisionTreeRegressor 호출( max_depth= 4, min_samples_split= 5, random_state= 1234)\n",
    "\n",
    "\n",
    "# fit\n",
    "\n",
    "# predict\n",
    "\n",
    "# 평가 report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importances_  종속변수(car_type에 영향을 미치는 정도) -> feature_importances_로 분기 한다\n",
    "\n",
    "\n",
    "# feature_importances_\n",
    "\n",
    "# feature_importances_시각화\n",
    "sns.barplot( x='imp_2', y='feature', data=model_imp_2.head(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_tree 시각화\n",
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(25,10))\n",
    "a = plot_tree(model_3_2, \n",
    "              feature_names= model_3_2.feature_names_in_, \n",
    "              class_names =  train_df_hk_3_2['expenditure'].unique(), \n",
    "              filled=True, \n",
    "              rounded=True,\n",
    "              max_depth= 3, \n",
    "              fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 시각화 DecisionTreeRegressor\n",
    "fig, ax = plt.subplots( nrows= 1 , ncols=2, figsize=(14, 5))\n",
    "sns.scatterplot( x=test_df_hk_3_2['salary'], y=test_df_hk_3_2['expenditure'], palette='Set1', ax=ax[0] )\n",
    "sns.scatterplot( x=test_df_hk_3_2['salary'], y=pred_tree_3_2                , palette='Set2', ax=ax[1] )\n",
    "\n",
    "ax[0].set_title('expenditure')\n",
    "ax[1].set_title('predict_tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth= 7\n",
    "# dummy ('gender', 'company')\n",
    "\n",
    "# train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# DecisionTreeRegressor 호출( max_depth= 4, min_samples_split= 5, random_state= 1234)\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# fit\n",
    "\n",
    "# predict\n",
    "\n",
    "# 평가 report\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 시각화 DecisionTreeRegressor( max_depth= 4와 max_depth= 7) 비교\n",
    "fig, ax = plt.subplots( nrows= 1 , ncols=3, figsize=(14, 5))\n",
    "sns.scatterplot( x=test_df_hk_3_2['salary'], y=test_df_hk_3_2['expenditure'], palette='Set1', ax=ax[0] )\n",
    "sns.scatterplot( x=test_df_hk_3_2['salary'], y=pred_tree_3_2                , palette='Set2', ax=ax[1] )\n",
    "sns.scatterplot( x=test_df_hk_3_2['salary'], y=pred_tree_3_2_7                , palette='Set2', ax=ax[2] )\n",
    "\n",
    "\n",
    "ax[0].set_title('expenditure')\n",
    "ax[1].set_title('predict_tree_4')\n",
    "ax[2].set_title('predict_tree_7')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. Naive Bayes 분류 실습 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 URL : https://todayisbetterthanyesterday.tistory.com/17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\displaystyle P(y|X)=\\frac{P(X|y)P(y)}{P(X)}$ &emsp;&emsp;&emsp;&emsp;    $\\mbox{Posterior}=\\frac{\\mbox{(Likelihood)}\\mbox{(Proposition prior probability)}}{\\mbox{Evidence prior probability}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$P\\left(y|x_{1},x_{2},\\ldots,x_{n}\\right)= \\frac{P\\left(x_{1},x_{2},\\ldots,x_{n}|y\\right)P(y)}{x=\\left(x_{1},x_{2},\\ldots,x_{n}\\right)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$= \\frac{P(x_1|y)P(x_2|y)P(x_3|y)...P(x_p|y)P(y)}{P(x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나이브 베이즈 분류에는 대표적으로 2가지 경우가 존재 \n",
    "\n",
    "<br> 1. 설명변수가 연속형 변수일 때, <b>Gaussian Naive Bayes</b> (가우시안 나이브 베이즈)\n",
    "<br> 2. 설명변수가 범주형 변수일 때, <b>Multinomial Naive Bayes</b> (다항 나이브 베이즈) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> train_df_hk_3, test_df_hk_3 테이블 사용\n",
    "<br><b>종속변수</b> : car_type\n",
    "<br><b>독립변수</b> : gender, height, age, salary, expenditure, company(명목변수 모두 더미변수화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로딩  train_df_hk_3\n",
    "train_df_hk_3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GaussianNB, MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car_type예측, MultinomialNB() 모델링\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predict_proba, 확률값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classification_report (MultinomialNB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# classification_report (tree)\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2. $\\pi$(파이) Quiz Naive Bayes 회귀 실습\n",
    "\n",
    "<br><실행순서>\n",
    "<br>1. basetable1 사용\n",
    "<br>2. 종속변수 : expenditure\n",
    "<br>3. 독립변수 : gender, height, age, company, salary (명목형변수 dummy화)\n",
    "<br>4. train_test_split(random_state=123, train_size= 0.7)\n",
    "<br>5. 나이브베이즈 GaussianNB()으로 모델링 하고 예측하여 mse를 구하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1) 파일 로딩\n",
    "basetable1\n",
    "\n",
    "# step2) 필요 데이터 프레임 생성 (종속변수 : expenditure 독립변수 : gender, height, age, company, salary)\n",
    "\n",
    "\n",
    "# step3) dummy화\n",
    "\n",
    "\n",
    "# step4) train_test_split(random_state=123, train_size= 0.7)\n",
    "\n",
    "# step5) GaussianNB() 모델링\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "\n",
    "# fit\n",
    "\n",
    "\n",
    "# GaussianNB() 예측\n",
    "\n",
    "# GaussianNB() 평가, mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. K-Nearest Neighbor\n",
    "\n",
    "\n",
    "<br>train_df_hk_3, test_df_hk_3 사용\n",
    "<br><b>종속변수</b> : car_type\n",
    "<br><b>독립변수</b> : height, age, salary, expenditure(정규화 시행), 성별(더미변수만 추가) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로딩\n",
    "train_df_hk_3\n",
    "test_df_hk_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset 준비,  StandardScaling, concat\n",
    "\n",
    "# StandardScaling ['height', 'age', 'salary', 'expenditure']\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# train.transform, pd.DataFrame\n",
    "\n",
    "\n",
    "# train concat, reset_index(drop=True) 기존 index 삭제\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset 준비,  train StandardScaler 적용, concat\n",
    "\n",
    "# test.transform, pd.DataFrame\n",
    "\n",
    "\n",
    "# test concat, reset_index(drop=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test df 생성 , ['car_type', 'height_st', 'age_st', 'salary_st', 'expenditure_st', 'gender_F', 'gender_M']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNeighborsClassifier 호출\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNeighborsClassifier 모델링(n_neighbors=3), fitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNeighborsClassifier 예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNeighborsClassifier 확률값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classification_report (KNeighborsClassifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classification_report (MultinomialNB)  비교\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# classification_report (tree) 비교\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  $\\Sigma$ (시그마) Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quiz 1) diamond 데이터 셋 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다이아몬드 특성을 바탕으로 cut 분류 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터(diamonds.csv) 사이즈 : 53940 X 10\n",
    "<br> \n",
    "<br> <b>carat:</b> weight of the diamond (0.2--5.01)\n",
    "<br> <b>cut:</b> quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
    "<br> <b>color:</b> diamond colour, from D (best) to J (worst)\n",
    "<br> <b>clarity:</b> a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
    "<br> <b>depth:</b> total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79)\n",
    "<br> <b>table:</b> width of top of diamond relative to widest point (43--95) \n",
    "<br> <b>price:</b> price in US dollars (us326--us18,823)\n",
    "<br> <b>x:</b> length in mm (0--10.74)\n",
    "<br> <b>y:</b> width in mm (0--58.9)\n",
    "<br> <b>z:</b> depth in mm (0--31.8)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "목표: 단가 높은 다이아몬드 판단하기  \n",
    "<br>1. 캐럿당 가격을 알 수 있는 <b>carat_per_price</b> 합성변수 생성, carat_per_price = price / carat \n",
    "<br> 상위 25% 값인 약 4949.5997 보다 높으면 1, 나머지는 0 으로하는 target 변수 생성 \n",
    "<br>2. cut, color, clarity one-hot인코딩(dummy) 진행 price 제외한 모든 수치형 변수 독립변수로 추가( 종속변수 제외, 총 26개 변수)\n",
    "<br>3. 트레이닝 데이터셋, 테스트 데이터셋 7:3 비율로 생성(random_state=123)\n",
    "<br>4. from sklearn.tree import DecisionTreeClassifier 활용 \n",
    "<br>(불순도 기준: Gini, Max Depth: 6, Min Samples Splits: 5, Seed: 1234, 그 외: Default)\n",
    "<br> 26개 독립변수를 활용하여 target을 분류 예측하는 의사결정 나무 모델 적합 \n",
    "<br> 5. 테스트 셋(16,182 rows)을 바탕으로 예측하고 실제값과 비교해 f1_score를 구하시오(target 1 기준으로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로딩\n",
    "df_dia = pd.read_csv('.\\\\data\\\\diamonds.csv')\n",
    "df_dia.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1) 1. 캐럿당 가격을 알 수 있는 <b>carat_per_price</b> 합성변수 생성, carat_per_price = price / carat\n",
    "\n",
    "# step1) 상위 25% 값인 약 4950 보다 높으면 1, 나머지는 0 으로하는 target 변수 생성\n",
    "\n",
    "# value_counts\n",
    "\n",
    "# step2) cut, color, clarity one-hot인코딩, price 제외한 모든 수치형 변수 독립변수로 추가( 종속변수 제외, 총 26개 변수)\n",
    "\n",
    "# concat\n",
    "\n",
    "# train_test_split(7:3 비율로 생성, random_state=123)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# step4) DecisionTreeClassifier 활용 (불순도 기준: Gini, Max Depth: 6, Min Samples Splits: 5, Seed: 1234, 그 외: Default)\n",
    "# 26개 독립변수를 활용하여 target을 분류 예측하는 의사결정 나무 모델 적합\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# predict\n",
    "\n",
    "# crosstab\n",
    "\n",
    "# step5) f1_score를 구하시오(target 1 기준으로)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1668725563817,
     "user": {
      "displayName": "jinyang park",
      "userId": "06576046992691541404"
     },
     "user_tz": -540
    },
    "id": "U7bJWMjX4d89",
    "outputId": "364f40c0-7f47-4b94-aedd-94f53fe84574"
   },
   "outputs": [],
   "source": [
    "# feature_importances_ 확인\n",
    "\n",
    "# 시각화\n",
    "sns.barplot( x='imp_3', y='feature', data=model_imp_3.head(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "의사결정 나무 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(25,10))\n",
    "a = plot_tree(model_tree, \n",
    "              feature_names= model_tree.feature_names_in_, \n",
    "              class_names= str(dia_train['target'].unique()), \n",
    "              filled=True, \n",
    "              rounded=True,\n",
    "              max_depth= 3, \n",
    "              fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quiz 2)  와인 데이터 셋 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "와인의 다양한 특성 바탕으로 KNN 분류 예측 모델 생성 \n",
    "\n",
    "데이터(sklearn_wine.csv) 사이즈 : 178 X 14\n",
    "\n",
    "<br><b>alcohol</b>: 알코올\n",
    "<br><b>malic acid</b>: 말산\n",
    "<br><b>ash</b> : 회분\n",
    "<br><b>alcalinity of ash</b>: 회분의 알칼리도\n",
    "<br><b>magnesium</b>: 마그네슘\n",
    "<br><b>total phenols</b>: 총 폴리페놀\n",
    "<br><b>color intensity</b>: 색상의 강도\n",
    "<br><b>hue</b>: 색상 \n",
    "\n",
    "등\n",
    "\n",
    "목표: 와인의 화학적 특성을 바탕으로 와인 종류를 예측하기 \n",
    "1. 종속변수는 target 변수에서 항목이 1일경우 1, 나머지는 0으로 하는 칼럼을 만들고 target 변수 그대로 덮어쓴다.\n",
    "2. 독립변수는 13개 수치형 변수 그대로 활용하되 정규화(minmax)를 통해 단위를 통일한다. \n",
    "3. 트레이닝 데이터셋과 테스트 데이터 셋 7:3으로 분할 한다.(random_state = 123으로 설정) \n",
    "4. K-Nearest Neighbor 알고리즘을 활용하되 n_neighbor 수는 3으로 설정한다. \n",
    "5. 트레이닝 데이터셋을 바탕으로 모델을 학습하고 학습한 모델을 바탕으로 테스트 데이터셋을 분류 예측한다. \n",
    "6. recall 값과 f1값을 구하시오 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로딩\n",
    "df_wine = pd.read_csv('.\\\\data\\\\sklearn_wine.csv').drop('Unnamed: 0', axis=1)\n",
    "df_wine[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1) 종속변수는 target 변수에서 항목이 1일경우 1, 나머지는 0으로 하는 칼럼을 만들고 target 변수 그대로 덮어쓴다.\n",
    "\n",
    "\n",
    "# step2) 독립변수는 13개 수치형 변수 그대로 활용하되 정규화(minmax)를 통해 단위를 통일한다. \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# step3) 트레이닝 데이터셋과 테스트 데이터 셋 7:3으로 분할 한다.(random_state = 123으로 설정) \n",
    "\n",
    "\n",
    "# step4) K-Nearest Neighbor 알고리즘을 활용하되 n_neighbor 수는 3으로 설정한다\n",
    "\n",
    "\n",
    "# step5) 테스트 데이터셋을 분류 예측 \n",
    "# step6) recall 값을 구하시오 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Omega$(오메가) Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 타이타닉 생존자 분류하기 \n",
    "\n",
    "<br> 데이터셋(seaborn_titanic.csv): seaborn library dataset\n",
    "<br> 891 rows × 15 columns\n",
    "\n",
    "<br><b> survived</b> : 생존 여부( 0: 사망/ 1: 생존) \n",
    "<br><b> pclass</b> : 좌석등급(1/2/3)\n",
    "<br><b> sex</b> : 성별 \n",
    "<br><b> age</b> : 나이 \n",
    "<br><b> sibsp</b> : 형제자매 + 배우자 인원수 \n",
    "<br><b> parch</b> : 부모 + 자식 인원수 \n",
    "<br><b> fare</b> : 요금 \n",
    "<br><b> embarked</b> : 탑승 항구(S/C/Q)\n",
    "<br><b> class</b> : 좌석등급(First, Second, Third) \n",
    "<br><b> who</b> : 성별 \n",
    "<br><b> deck</b> : 선실 고유번호 가장 앞자리 알파벳(A/B/C/D/E/F/G)\n",
    "<br><b> embark_town</b> : 탑승 항구(Southampon/Cherbourg/Queenstown) \n",
    "<br><b> alive</b> : 생존여부 \n",
    "<br><b> alone</b> : 혼자인지 여부 \n",
    "\n",
    "등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><실행순서>\n",
    "<br>1. 종속변수 : survived / 독립변수 : sex, age, sibsp, parch, fare, embarked, class로 한다\n",
    "<br>2. 해당 변수 중 하나라도 결측치가 있는 데이터 셋은 제외한다 \n",
    "<br>3. 독립변수 중 sex, embarked, class는 더미변수화 하며 drop_first 옵션은 True로 지정한다 \n",
    "<br>4. 수치형 독립변수 중 가장 왜도가 큰 변수 값은 log변환 한다.(변환시 np.log( 1+ 변수) 활용 할 것) \n",
    "<br>5. 트레이닝셋:테스트셋 7:3으로 분할한다(random_state =123)  \n",
    "<br>6. sklearn 라이브러리 활용 로지스틱 회귀분석 트레이닝셋 학습을 진행한다(파라미터 값 C=100000 ,solver='newton-cg' 적용)\n",
    "<br>7. 학습한 모델을 바탕으로 테스트셋 예측을 진행한다. \n",
    "<br>   이때 f1-score를 높이기 위해 예측값은 \n",
    "       확률값을 확인하여 target=1로 예측한 확률값이 0.4보다 큰 경우에는 1로 나머지는 0으로 분류한다        \n",
    "<br>8. 7번의 단계를 모두 수행한 후 class 1에 대한 변경된 f1-score값은 무엇인가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로딩\n",
    "df_titanic = pd.read_csv('.\\\\data\\\\seaborn_titanic.csv')\n",
    "df_titanic[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1) 종속변수 : survived / 독립변수 : sex, age, sibsp, parch, fare, embarked, class\n",
    "\n",
    "# step2) 해당 변수 중 하나라도 결측치가 있는 데이터 셋은 제외한다\n",
    "\n",
    "# step3) 독립변수 중 sex, embarked, class는 더미변수화 하며 drop_first 옵션은 True로 지정한다\n",
    "\n",
    "# skew\n",
    "\n",
    "# step4) 수치형 독립변수 중 가장 왜도가 큰 변수 값은 log변환 한다.(변환시 np.log( 1+ 변수) 활용 할 것)\n",
    "\n",
    "# step5) 트레이닝셋:테스트셋 7:3으로 분할한다(random_state =123)\n",
    "\n",
    "# step6) sklearn 라이브러리 활용 로지스틱 회귀분석 트레이닝셋 학습을 진행한다(파라미터 값 C=100000 ,solver='newton-cg' 적용)\n",
    "\n",
    "# step7) 테스트셋 예측, 이때 f1-score를 높이기 위해 \n",
    "# 예측값은 확률값을 확인하여 target=1로 예측한 확률값이 0.4보다 큰 경우에는 1로 나머지는 0으로 분류한다\n",
    "\n",
    "# predict_proba\n",
    "\n",
    "# step7) 테스트셋 예측, 이때 f1-score를 높이기 위해 \n",
    "# 예측값은 확률값을 확인하여 target=1로 예측한 확률값이 0.4보다 큰 경우에는 1로 나머지는 0으로 분류한다\n",
    "\n",
    "# step8) 7번의 단계를 모두 수행한 후 class 1에 대한 변경된 f1-score값은 무엇인가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMDMucM2pMTNZILG4KX61Uv",
   "collapsed_sections": [
    "4JTxsWF-5sXG",
    "hfMi2HeL4piH",
    "5YwW9JcI1BcB",
    "0DC3DnJKED-q",
    "7OEylfG6Ou24",
    "z4IpIXV-edh3",
    "vhWiJegbvSiL",
    "rttRLvNIl51S",
    "X7ZNaAeiw8e1",
    "LrwKIIBM3AuA",
    "JpMOZEbbpdH6",
    "Ht5WvWhG6tun",
    "joz0fttoOWYJ"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
